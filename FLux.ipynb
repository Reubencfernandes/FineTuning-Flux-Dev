{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOuuDVCD4oZplVabYsOBe4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7af3526f4c0c4acd8dd496c67f6768c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34d836865c49457c8e977cba77b54c07",
              "IPY_MODEL_0a67a2ebb8434d4dad6e625e82403006",
              "IPY_MODEL_d36c972b41c64d528b7db3d1db13ad8a"
            ],
            "layout": "IPY_MODEL_235605e789984788bd4e57f81df85ec5"
          }
        },
        "34d836865c49457c8e977cba77b54c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4492ecfb4644908279401d17429ca2",
            "placeholder": "​",
            "style": "IPY_MODEL_a317e29a831b4638abd93cbfe5010820",
            "value": "Downloading shards: 100%"
          }
        },
        "0a67a2ebb8434d4dad6e625e82403006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f427ae7d86e424fa4605a9e1038bc8e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc284a42e0954923966b6b288fe087f6",
            "value": 2
          }
        },
        "d36c972b41c64d528b7db3d1db13ad8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ad7b0614bb94441bd0414013014fe2c",
            "placeholder": "​",
            "style": "IPY_MODEL_fc3ee307db144a9cab77d08fdf02856e",
            "value": " 2/2 [00:00&lt;00:00, 151.40it/s]"
          }
        },
        "235605e789984788bd4e57f81df85ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4492ecfb4644908279401d17429ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a317e29a831b4638abd93cbfe5010820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f427ae7d86e424fa4605a9e1038bc8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc284a42e0954923966b6b288fe087f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ad7b0614bb94441bd0414013014fe2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3ee307db144a9cab77d08fdf02856e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5685595b2804a5e88150f97ffcc250e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a214de4975f4378b1431aeb165f2335",
              "IPY_MODEL_cb7e23bf5e1d476e82c8a188cb946648",
              "IPY_MODEL_48a56a422ac04cb1b727eb70d464aaba"
            ],
            "layout": "IPY_MODEL_58c59fb9a5624f479b23a7bc67fe2bbe"
          }
        },
        "2a214de4975f4378b1431aeb165f2335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872ec327e85f4ea18abf7114c71957b4",
            "placeholder": "​",
            "style": "IPY_MODEL_93c835539a5e4eb9a647e1c27e163963",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cb7e23bf5e1d476e82c8a188cb946648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_509f5ebf709649049b9770d97426789f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8527c7d0ca2249969d83a435fa6e0990",
            "value": 2
          }
        },
        "48a56a422ac04cb1b727eb70d464aaba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a364d99b6414ae5b0322446e0ab76b0",
            "placeholder": "​",
            "style": "IPY_MODEL_e41494d92a48427fadf804b2e5a2490d",
            "value": " 2/2 [00:00&lt;00:00,  2.37it/s]"
          }
        },
        "58c59fb9a5624f479b23a7bc67fe2bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872ec327e85f4ea18abf7114c71957b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93c835539a5e4eb9a647e1c27e163963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "509f5ebf709649049b9770d97426789f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8527c7d0ca2249969d83a435fa6e0990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a364d99b6414ae5b0322446e0ab76b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41494d92a48427fadf804b2e5a2490d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reubencfernandes/FineTuning-Flux-Dev/blob/main/FLux.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLxw3jk6x7nK",
        "outputId": "c907f30d-993f-4a29-f40e-4fdc67d965c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai-toolkit'...\n",
            "remote: Enumerating objects: 4015, done.\u001b[K\n",
            "remote: Counting objects: 100% (2004/2004), done.\u001b[K\n",
            "remote: Compressing objects: 100% (259/259), done.\u001b[K\n",
            "remote: Total 4015 (delta 1876), reused 1776 (delta 1741), pack-reused 2011 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4015/4015), 29.70 MiB | 43.83 MiB/s, done.\n",
            "Resolving deltas: 100% (3055/3055), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ostris/ai-toolkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/dataset"
      ],
      "metadata": {
        "id": "7rhnDlui02iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MynpRYOs0-Sr",
        "outputId": "f47e5402-6b50-449d-8d47-e757b1665810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submodule 'repositories/batch_annotator' (https://github.com/ostris/batch-annotator) registered for path 'repositories/batch_annotator'\n",
            "Submodule 'repositories/ipadapter' (https://github.com/tencent-ailab/IP-Adapter.git) registered for path 'repositories/ipadapter'\n",
            "Submodule 'repositories/leco' (https://github.com/p1atdev/LECO) registered for path 'repositories/leco'\n",
            "Submodule 'repositories/sd-scripts' (https://github.com/kohya-ss/sd-scripts.git) registered for path 'repositories/sd-scripts'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator'...\n",
            "Cloning into '/content/ai-toolkit/repositories/ipadapter'...\n",
            "Cloning into '/content/ai-toolkit/repositories/leco'...\n",
            "Cloning into '/content/ai-toolkit/repositories/sd-scripts'...\n",
            "Submodule path 'repositories/batch_annotator': checked out '420e142f6ad3cc14b3ea0500affc2c6c7e7544bf'\n",
            "Submodule 'repositories/controlnet' (https://github.com/lllyasviel/ControlNet-v1-1-nightly.git) registered for path 'repositories/batch_annotator/repositories/controlnet'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator/repositories/controlnet'...\n",
            "Submodule path 'repositories/batch_annotator/repositories/controlnet': checked out 'e2b44154b72965c5e11b1ccee941d550682e4701'\n",
            "Submodule path 'repositories/ipadapter': checked out '5a18b1f3660acaf8bee8250692d6fb3548a19b14'\n",
            "Submodule path 'repositories/leco': checked out '9294adf40218e917df4516737afb13f069a6789d'\n",
            "Submodule path 'repositories/sd-scripts': checked out 'b78c0e2a69e52ce6c79abc6c8c82d1a9cabcf05c'\n",
            "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-rhg_h4b3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-rhg_h4b3\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit ad5ecd1251472dbc69da1268671d41bc2d8c1caa\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.46.2)\n",
            "Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 6))\n",
            "  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatten_json (from -r requirements.txt (line 7))\n",
            "  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Collecting oyaml (from -r requirements.txt (line 9))\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.17.1)\n",
            "Collecting kornia (from -r requirements.txt (line 11))\n",
            "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting invisible-watermark (from -r requirements.txt (line 12))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.8.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
            "Collecting albumentations==1.4.15 (from -r requirements.txt (line 16))\n",
            "  Downloading albumentations-1.4.15-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting albucore==0.0.16 (from -r requirements.txt (line 17))\n",
            "  Downloading albucore-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.9.2)\n",
            "Collecting omegaconf (from -r requirements.txt (line 19))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting k-diffusion (from -r requirements.txt (line 20))\n",
            "  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting open_clip_torch (from -r requirements.txt (line 21))\n",
            "  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.0.11)\n",
            "Collecting prodigyopt (from -r requirements.txt (line 23))\n",
            "  Downloading prodigyopt-1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting controlnet_aux==0.0.7 (from -r requirements.txt (line 24))\n",
            "  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv (from -r requirements.txt (line 25))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 26))\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting hf_transfer (from -r requirements.txt (line 27))\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting lpips (from -r requirements.txt (line 28))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch_fid (from -r requirements.txt (line 29))\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting optimum-quanto==0.2.4 (from -r requirements.txt (line 30))\n",
            "  Downloading optimum_quanto-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.2.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.26.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (0.13.2)\n",
            "Collecting gradio (from -r requirements.txt (line 34))\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (8.0.4)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.24.0)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (4.10.0.84)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (8.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (4.10.0.84)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (11.0.0)\n",
            "Collecting ninja (from optimum-quanto==0.2.4->-r requirements.txt (line 30))\n",
            "  Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (4.66.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from flatten_json->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (75.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.1.3)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia->-r requirements.txt (line 11))\n",
            "  Downloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting PyWavelets>=1.1.1 (from invisible-watermark->-r requirements.txt (line 12))\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 14)) (5.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (2.23.4)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 19))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clean-fid (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting dctorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n",
            "Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from k-diffusion->-r requirements.txt (line 20)) (0.18.7)\n",
            "Collecting ftfy (from open_clip_torch->-r requirements.txt (line 21))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.27.2)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.10.11)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (2.2.2)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.13.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio->-r requirements.txt (line 34))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->-r requirements.txt (line 35)) (1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (0.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (13.9.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 21)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.21.0)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 20)) (4.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2.2.3)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (1.3.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (4.0.11)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (5.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (0.1.2)\n",
            "Downloading albumentations-1.4.15-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.16-py3-none-any.whl (9.5 kB)\n",
            "Downloading optimum_quanto-0.2.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
            "Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n",
            "Downloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
            "Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lycoris-lora, controlnet_aux, diffusers, antlr4-python3-runtime\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lycoris-lora: filename=lycoris_lora-1.8.3-py3-none-any.whl size=77134 sha256=523cd341a9c3c846bc78c6b31f279e28df702e47b772e179887d13664c539bc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/d8/ac/e1feba5dec18685dac32ff2465ea1908cbe6a919a0c008a215\n",
            "  Building wheel for controlnet_aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274344 sha256=a8f9e2310e25190b4b5c7d7bb31bb674e44c987392a954b5d7b51971213fdbd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/3e/93/6678b4c0bc2ec31d53409b25d4189cbb08bae843e8b2b78e52\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.32.0.dev0-py3-none-any.whl size=2977364 sha256=72d4af33ab1f3bd5c555e702351516c9bbedfd6be0d6baca9cfcb68dd71ab54c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-na_jumxe/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=10678bc6dd3e20473d486bca4e6dc19dfac832b89e1b115d6894b5f910fb7cd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built lycoris-lora controlnet_aux diffusers antlr4-python3-runtime\n",
            "Installing collected packages: trampoline, pydub, antlr4-python3-runtime, websockets, uvicorn, tomlkit, semantic-version, ruff, PyWavelets, python-multipart, python-dotenv, prodigyopt, oyaml, omegaconf, ninja, markupsafe, kornia-rs, hf_transfer, ftfy, flatten_json, ffmpy, aiofiles, starlette, albucore, safehttpx, gradio-client, fastapi, diffusers, albumentations, torchsde, torchdiffeq, optimum-quanto, kornia, jsonmerge, invisible-watermark, gradio, dctorch, bitsandbytes, pytorch_fid, lycoris-lora, lpips, clip-anytorch, clean-fid, open_clip_torch, k-diffusion, controlnet_aux\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.19\n",
            "    Uninstalling albucore-0.0.19:\n",
            "      Successfully uninstalled albucore-0.0.19\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.31.0\n",
            "    Uninstalling diffusers-0.31.0:\n",
            "      Successfully uninstalled diffusers-0.31.0\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "Successfully installed PyWavelets-1.7.0 aiofiles-23.2.1 albucore-0.0.16 albumentations-1.4.15 antlr4-python3-runtime-4.9.3 bitsandbytes-0.44.1 clean-fid-0.1.35 clip-anytorch-2.6.0 controlnet_aux-0.0.7 dctorch-0.1.2 diffusers-0.32.0.dev0 fastapi-0.115.5 ffmpy-0.4.0 flatten_json-0.1.14 ftfy-6.3.1 gradio-5.6.0 gradio-client-1.4.3 hf_transfer-0.1.8 invisible-watermark-0.2.0 jsonmerge-1.9.2 k-diffusion-0.1.1.post1 kornia-0.7.4 kornia-rs-0.1.7 lpips-0.1.4 lycoris-lora-1.8.3 markupsafe-2.1.5 ninja-1.11.1.2 omegaconf-2.3.0 open_clip_torch-2.29.0 optimum-quanto-0.2.4 oyaml-1.0 prodigyopt-1.0 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.12 pytorch_fid-0.3.0 ruff-0.8.0 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 torchdiffeq-0.2.5 torchsde-0.2.6 trampoline-0.1.2 uvicorn-0.32.1 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Prompt for the token\n",
        "hf_token = getpass.getpass('Enter your HF access token and press enter: ')\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "print(\"HF_TOKEN environment variable has been set.\")"
      ],
      "metadata": {
        "id": "OYEledTs1aQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27378b21-e5fd-4cb7-f0b5-e8f91fed2870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your HF access token and press enter: ··········\n",
            "HF_TOKEN environment variable has been set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/ai-toolkit')\n",
        "from toolkit.job import run_job\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
      ],
      "metadata": {
        "id": "mfFyFyOs1kXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "job_to_run = OrderedDict([\n",
        "    ('job', 'extension'),\n",
        "    ('config', OrderedDict([\n",
        "        # this name will be the folder and filename name\n",
        "        ('name', 'my_first_flux_lora_v1'),\n",
        "        ('process', [\n",
        "            OrderedDict([\n",
        "                ('type', 'sd_trainer'),\n",
        "                # root folder to save training sessions/samples/weights\n",
        "                ('training_folder', '/content/output'),\n",
        "                # uncomment to see performance stats in the terminal every N steps\n",
        "                ('performance_log_every', 1000),\n",
        "                ('device', 'cuda:0'),\n",
        "                # if a trigger word is specified, it will be added to captions of training data if it does not already exist\n",
        "                # alternatively, in your captions you can add [trigger] and it will be replaced with the trigger word\n",
        "                # ('trigger_word', 'image'),\n",
        "                ('network', OrderedDict([\n",
        "                    ('type', 'lora'),\n",
        "                    ('linear', 16),\n",
        "                    ('linear_alpha', 16)\n",
        "                ])),\n",
        "                ('save', OrderedDict([\n",
        "                    ('dtype', 'float16'),  # precision to save\n",
        "                    ('save_every', 250),  # save every this many steps\n",
        "                    ('max_step_saves_to_keep', 4)  # how many intermittent saves to keep\n",
        "                ])),\n",
        "                ('datasets', [\n",
        "                    OrderedDict([\n",
        "                        ('folder_path', '/content/dataset'),\n",
        "                        ('caption_ext', 'txt'),\n",
        "                        ('caption_dropout_rate', 0.05),  # will drop out the caption 5% of time\n",
        "                        ('shuffle_tokens', False),  # shuffle caption order, split by commas\n",
        "                        ('cache_latents_to_disk', True),  # leave this true unless you know what you're doing\n",
        "                        ('resolution', [512, 768, 1024])  # flux enjoys multiple resolutions\n",
        "                    ])\n",
        "                ]),\n",
        "                ('train', OrderedDict([\n",
        "                    ('batch_size', 1),\n",
        "                    ('steps', 2000),  # total number of steps to train 500 - 4000 is a good range\n",
        "                    ('gradient_accumulation_steps', 1),\n",
        "                    ('train_unet', True),\n",
        "                    ('train_text_encoder', False),  # probably won't work with flux\n",
        "                    ('content_or_style', 'balanced'),  # content, style, balanced\n",
        "                    ('gradient_checkpointing', True),  # need the on unless you have a ton of vram\n",
        "                    ('noise_scheduler', 'flowmatch'),  # for training only\n",
        "                    ('optimizer', 'adamw8bit'),\n",
        "                    ('lr', 1e-4),\n",
        "\n",
        "                    # uncomment this to skip the pre training sample\n",
        "                    # ('skip_first_sample', True),\n",
        "\n",
        "                    # uncomment to completely disable sampling\n",
        "                    # ('disable_sampling', True),\n",
        "\n",
        "                    # uncomment to use new vell curved weighting. Experimental but may produce better results\n",
        "                    # ('linear_timesteps', True),\n",
        "\n",
        "                    # ema will smooth out learning, but could slow it down. Recommended to leave on.\n",
        "                    ('ema_config', OrderedDict([\n",
        "                        ('use_ema', True),\n",
        "                        ('ema_decay', 0.99)\n",
        "                    ])),\n",
        "\n",
        "                    # will probably need this if gpu supports it for flux, other dtypes may not work correctly\n",
        "                    ('dtype', 'bf16')\n",
        "                ])),\n",
        "                ('model', OrderedDict([\n",
        "                    # huggingface model name or path\n",
        "                    ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n",
        "                    ('is_flux', True),\n",
        "                    ('quantize', True),  # run 8bit mixed precision\n",
        "                    #('low_vram', True),  # uncomment this if the GPU is connected to your monitors. It will use less vram to quantize, but is slower.\n",
        "                ])),\n",
        "                ('sample', OrderedDict([\n",
        "                    ('sampler', 'flowmatch'),  # must match train.noise_scheduler\n",
        "                    ('sample_every', 250),  # sample every this many steps\n",
        "                    ('width', 1024),\n",
        "                    ('height', 1024),\n",
        "                    ('prompts', [\n",
        "                        # you can add [trigger] to the prompts here and it will be replaced with the trigger word\n",
        "                        #'[trigger] holding a sign that says \\'I LOVE PROMPTS!\\'',\n",
        "                        '[trigger] is standing in a dimly lit street in Japan, wearing a sharp suit and tie, exuding a mysterious and confident aura. The background features glowing storefront signs with Japanese text, a parked car, and a quiet urban atmosphere, perfectly blending modernity with a cinematic noir vibe',\n",
        "                        'A professional portrait of [trigger], wearing a navy blue suit and red tie. The background features the Indian flag and the Vatican flag, symbolizing an official or governmental setting. The lighting is soft, highlighting [trigger] face and creating a polished, formal appearance. [Trigger] has a confident and calm demeanor.',\n",
        "                    ]),\n",
        "                    ('neg', ''),  # not used on flux\n",
        "                    ('seed', 42),\n",
        "                    ('walk_seed', True),\n",
        "                    ('guidance_scale', 4),\n",
        "                    ('sample_steps', 20)\n",
        "                ]))\n",
        "            ])\n",
        "        ])\n",
        "    ])),\n",
        "    # you can add any additional meta info here. [name] is replaced with config name at top\n",
        "    ('meta', OrderedDict([\n",
        "        ('name', '[name]'),\n",
        "        ('version', '1.0')\n",
        "    ]))\n",
        "])"
      ],
      "metadata": {
        "id": "_rZd2MIr1z5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_job(job_to_run)"
      ],
      "metadata": {
        "id": "AdfJjFCh2G2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7af3526f4c0c4acd8dd496c67f6768c3",
            "34d836865c49457c8e977cba77b54c07",
            "0a67a2ebb8434d4dad6e625e82403006",
            "d36c972b41c64d528b7db3d1db13ad8a",
            "235605e789984788bd4e57f81df85ec5",
            "2c4492ecfb4644908279401d17429ca2",
            "a317e29a831b4638abd93cbfe5010820",
            "7f427ae7d86e424fa4605a9e1038bc8e",
            "cc284a42e0954923966b6b288fe087f6",
            "2ad7b0614bb94441bd0414013014fe2c",
            "fc3ee307db144a9cab77d08fdf02856e",
            "d5685595b2804a5e88150f97ffcc250e",
            "2a214de4975f4378b1431aeb165f2335",
            "cb7e23bf5e1d476e82c8a188cb946648",
            "48a56a422ac04cb1b727eb70d464aaba",
            "58c59fb9a5624f479b23a7bc67fe2bbe",
            "872ec327e85f4ea18abf7114c71957b4",
            "93c835539a5e4eb9a647e1c27e163963",
            "509f5ebf709649049b9770d97426789f",
            "8527c7d0ca2249969d83a435fa6e0990",
            "0a364d99b6414ae5b0322446e0ab76b0",
            "e41494d92a48427fadf804b2e5a2490d"
          ]
        },
        "collapsed": true,
        "outputId": "d4948aaf-b4a1-42b8-aa09-ea9e007febbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"type\": \"sd_trainer\",\n",
            "    \"training_folder\": \"/content/output\",\n",
            "    \"performance_log_every\": 1000,\n",
            "    \"device\": \"cuda:0\",\n",
            "    \"network\": {\n",
            "        \"type\": \"lora\",\n",
            "        \"linear\": 16,\n",
            "        \"linear_alpha\": 16\n",
            "    },\n",
            "    \"save\": {\n",
            "        \"dtype\": \"float16\",\n",
            "        \"save_every\": 250,\n",
            "        \"max_step_saves_to_keep\": 4\n",
            "    },\n",
            "    \"datasets\": [\n",
            "        {\n",
            "            \"folder_path\": \"/content/dataset\",\n",
            "            \"caption_ext\": \"txt\",\n",
            "            \"caption_dropout_rate\": 0.05,\n",
            "            \"shuffle_tokens\": false,\n",
            "            \"cache_latents_to_disk\": true,\n",
            "            \"resolution\": [\n",
            "                512,\n",
            "                768,\n",
            "                1024\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"train\": {\n",
            "        \"batch_size\": 1,\n",
            "        \"steps\": 2000,\n",
            "        \"gradient_accumulation_steps\": 1,\n",
            "        \"train_unet\": true,\n",
            "        \"train_text_encoder\": false,\n",
            "        \"content_or_style\": \"balanced\",\n",
            "        \"gradient_checkpointing\": true,\n",
            "        \"noise_scheduler\": \"flowmatch\",\n",
            "        \"optimizer\": \"adamw8bit\",\n",
            "        \"lr\": 0.0001,\n",
            "        \"ema_config\": {\n",
            "            \"use_ema\": true,\n",
            "            \"ema_decay\": 0.99\n",
            "        },\n",
            "        \"dtype\": \"bf16\"\n",
            "    },\n",
            "    \"model\": {\n",
            "        \"name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n",
            "        \"is_flux\": true,\n",
            "        \"quantize\": true\n",
            "    },\n",
            "    \"sample\": {\n",
            "        \"sampler\": \"flowmatch\",\n",
            "        \"sample_every\": 250,\n",
            "        \"width\": 1024,\n",
            "        \"height\": 1024,\n",
            "        \"prompts\": [\n",
            "            \"[trigger] riding a horse\",\n",
            "            \"[trigger] is exploring the vibrant streets of Japan, surrounded by neon-lit signs.They are dressed casually, enjoying the blend of modern technology and rich cultural heritage\",\n",
            "            \"[trigger] is standing in a dimly lit street in Japan, wearing a sharp suit and tie, exuding a mysterious and confident aura. The background features glowing storefront signs with Japanese text, a parked car, and a quiet urban atmosphere, perfectly blending modernity with a cinematic noir vibe\",\n",
            "            \"a man showing off his cool new t shirt at the beach, a shark is jumping out of the water in the background\"\n",
            "        ],\n",
            "        \"neg\": \"\",\n",
            "        \"seed\": 42,\n",
            "        \"walk_seed\": true,\n",
            "        \"guidance_scale\": 4,\n",
            "        \"sample_steps\": 20\n",
            "    }\n",
            "}\n",
            "Using EMA\n",
            "\n",
            "#############################################\n",
            "# Running job: my_first_flux_lora_v1\n",
            "#############################################\n",
            "\n",
            "\n",
            "Running  1 process\n",
            "Loading Flux model\n",
            "Loading transformer\n",
            "Quantizing transformer\n",
            "Loading vae\n",
            "Loading t5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7af3526f4c0c4acd8dd496c67f6768c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5685595b2804a5e88150f97ffcc250e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantizing T5\n",
            "Loading clip\n",
            "making pipe\n",
            "preparing\n",
            "create LoRA network. base dim (rank): 16, alpha: 16\n",
            "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
            "create LoRA for Text Encoder: 0 modules.\n",
            "create LoRA for U-Net: 494 modules.\n",
            "enable LoRA for U-Net\n",
            "Dataset: /content/dataset\n",
            "  -  Preprocessing image dimensions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 71.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -  Found 13 images\n",
            "Bucket sizes for /content/dataset:\n",
            "448x576: 7 files\n",
            "576x448: 5 files\n",
            "384x576: 1 files\n",
            "3 buckets made\n",
            "Caching latents for /content/dataset\n",
            " - Saving latents to disk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Caching latents to disk: 100%|██████████| 13/13 [00:01<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: /content/dataset\n",
            "  -  Preprocessing image dimensions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 21862.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -  Found 13 images\n",
            "Bucket sizes for /content/dataset:\n",
            "640x832: 7 files\n",
            "832x640: 4 files\n",
            "704x512: 1 files\n",
            "576x832: 1 files\n",
            "4 buckets made\n",
            "Caching latents for /content/dataset\n",
            " - Saving latents to disk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Caching latents to disk: 100%|██████████| 13/13 [00:01<00:00, 12.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: /content/dataset\n",
            "  -  Preprocessing image dimensions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 24931.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -  Found 13 images\n",
            "Bucket sizes for /content/dataset:\n",
            "640x832: 5 files\n",
            "1152x832: 4 files\n",
            "832x1152: 2 files\n",
            "704x512: 1 files\n",
            "576x832: 1 files\n",
            "5 buckets made\n",
            "Caching latents for /content/dataset\n",
            " - Saving latents to disk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Caching latents to disk: 100%|██████████| 13/13 [00:00<00:00, 15.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating baseline samples before training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  12%|█▏        | 249/2000 [08:49<59:02,  2.02s/it, lr: 1.0e-04 loss: 4.822e-01]\n",
            "Generating Images:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  25%|██▌       | 1/4 [00:18<00:56, 18.80s/it]\u001b[A\n",
            "Generating Images:  50%|█████     | 2/4 [00:37<00:37, 18.76s/it]\u001b[A\n",
            "Generating Images:  75%|███████▌  | 3/4 [00:56<00:18, 18.73s/it]\u001b[A\n",
            "Generating Images: 100%|██████████| 4/4 [01:14<00:00, 18.73s/it]\u001b[A\n",
            "my_first_flux_lora_v1:  12%|█▏        | 249/2000 [08:49<59:02,  2.02s/it, lr: 1.0e-04 loss: 4.822e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving at step 250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  12%|█▏        | 249/2000 [08:51<59:02,  2.02s/it, lr: 1.0e-04 loss: 4.822e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/output/my_first_flux_lora_v1/optimizer.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  25%|██▍       | 499/2000 [17:36<47:02,  1.88s/it, lr: 1.0e-04 loss: 4.260e-01]\n",
            "Generating Images:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  25%|██▌       | 1/4 [00:18<00:56, 18.78s/it]\u001b[A\n",
            "Generating Images:  50%|█████     | 2/4 [00:37<00:37, 18.75s/it]\u001b[A\n",
            "Generating Images:  75%|███████▌  | 3/4 [00:56<00:18, 18.73s/it]\u001b[A\n",
            "Generating Images: 100%|██████████| 4/4 [01:14<00:00, 18.72s/it]\u001b[A\n",
            "my_first_flux_lora_v1:  25%|██▍       | 499/2000 [17:36<47:02,  1.88s/it, lr: 1.0e-04 loss: 4.260e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving at step 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  25%|██▍       | 499/2000 [17:38<47:02,  1.88s/it, lr: 1.0e-04 loss: 4.260e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/output/my_first_flux_lora_v1/optimizer.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  37%|███▋      | 749/2000 [26:21<44:01,  2.11s/it, lr: 1.0e-04 loss: 3.849e-01]\n",
            "Generating Images:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  25%|██▌       | 1/4 [00:18<00:56, 18.77s/it]\u001b[A\n",
            "Generating Images:  50%|█████     | 2/4 [00:37<00:37, 18.73s/it]\u001b[A\n",
            "Generating Images:  75%|███████▌  | 3/4 [00:56<00:18, 18.72s/it]\u001b[A\n",
            "Generating Images: 100%|██████████| 4/4 [01:14<00:00, 18.70s/it]\u001b[A\n",
            "my_first_flux_lora_v1:  37%|███▋      | 749/2000 [26:21<44:01,  2.11s/it, lr: 1.0e-04 loss: 3.849e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving at step 750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  37%|███▋      | 749/2000 [26:24<44:01,  2.11s/it, lr: 1.0e-04 loss: 3.849e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/output/my_first_flux_lora_v1/optimizer.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  50%|████▉     | 999/2000 [35:07<34:19,  2.06s/it, lr: 1.0e-04 loss: 5.727e-01]\n",
            "Generating Images:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  25%|██▌       | 1/4 [00:18<00:56, 18.81s/it]\u001b[A\n",
            "Generating Images:  50%|█████     | 2/4 [00:37<00:37, 18.75s/it]\u001b[A\n",
            "Generating Images:  75%|███████▌  | 3/4 [00:56<00:18, 18.74s/it]\u001b[A\n",
            "Generating Images: 100%|██████████| 4/4 [01:14<00:00, 18.73s/it]\u001b[A\n",
            "my_first_flux_lora_v1:  50%|████▉     | 999/2000 [35:07<34:19,  2.06s/it, lr: 1.0e-04 loss: 5.727e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving at step 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  50%|████▉     | 999/2000 [35:10<34:19,  2.06s/it, lr: 1.0e-04 loss: 5.727e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/output/my_first_flux_lora_v1/optimizer.pt\n",
            "\n",
            "Timer 'my_first_flux_lora_v1 Timer':\n",
            " - 2.1755s avg - train_loop, num = 10\n",
            " - 1.2697s avg - backward, num = 10\n",
            " - 0.6455s avg - predict_unet, num = 10\n",
            " - 0.2669s avg - reset_batch, num = 10\n",
            " - 0.1079s avg - optimizer_step, num = 10\n",
            " - 0.0682s avg - encode_prompt, num = 10\n",
            " - 0.0616s avg - calculate_loss, num = 10\n",
            " - 0.0023s avg - get_batch, num = 10\n",
            " - 0.0016s avg - preprocess_batch, num = 10\n",
            " - 0.0011s avg - prepare_noise, num = 10\n",
            " - 0.0005s avg - batch_cleanup, num = 10\n",
            " - 0.0003s avg - prepare_latents, num = 10\n",
            " - 0.0000s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - log_to_tensorboard, num = 10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  62%|██████▏   | 1249/2000 [43:54<26:44,  2.14s/it, lr: 1.0e-04 loss: 4.723e-01]\n",
            "Generating Images:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  25%|██▌       | 1/4 [00:18<00:56, 18.80s/it]\u001b[A\n",
            "Generating Images:  50%|█████     | 2/4 [00:37<00:37, 18.75s/it]\u001b[A\n",
            "Generating Images:  75%|███████▌  | 3/4 [00:56<00:18, 18.74s/it]\u001b[A\n",
            "Generating Images: 100%|██████████| 4/4 [01:14<00:00, 18.73s/it]\u001b[A\n",
            "my_first_flux_lora_v1:  62%|██████▏   | 1249/2000 [43:54<26:44,  2.14s/it, lr: 1.0e-04 loss: 4.723e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving at step 1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  62%|██████▏   | 1249/2000 [43:56<26:44,  2.14s/it, lr: 1.0e-04 loss: 4.723e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/output/my_first_flux_lora_v1/optimizer.pt\n",
            "Removing old save: /content/output/my_first_flux_lora_v1/my_first_flux_lora_v1_000000250.safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  75%|███████▍  | 1499/2000 [52:43<17:04,  2.05s/it, lr: 1.0e-04 loss: 4.338e-01]\n",
            "Generating Images:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  25%|██▌       | 1/4 [00:18<00:56, 18.78s/it]\u001b[A\n",
            "Generating Images:  50%|█████     | 2/4 [00:37<00:37, 18.75s/it]\u001b[A\n",
            "Generating Images:  75%|███████▌  | 3/4 [00:56<00:18, 18.73s/it]\u001b[A\n",
            "Generating Images: 100%|██████████| 4/4 [01:14<00:00, 18.73s/it]\u001b[A\n",
            "my_first_flux_lora_v1:  75%|███████▍  | 1499/2000 [52:43<17:04,  2.05s/it, lr: 1.0e-04 loss: 4.338e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving at step 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  75%|███████▍  | 1499/2000 [52:45<17:04,  2.05s/it, lr: 1.0e-04 loss: 4.338e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/output/my_first_flux_lora_v1/optimizer.pt\n",
            "Removing old save: /content/output/my_first_flux_lora_v1/my_first_flux_lora_v1_000000500.safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  87%|████████▋ | 1749/2000 [1:01:30<09:15,  2.21s/it, lr: 1.0e-04 loss: 4.383e-01]\n",
            "Generating Images:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  25%|██▌       | 1/4 [00:18<00:56, 18.77s/it]\u001b[A\n",
            "Generating Images:  50%|█████     | 2/4 [00:37<00:37, 18.74s/it]\u001b[A\n",
            "Generating Images:  75%|███████▌  | 3/4 [00:56<00:18, 18.73s/it]\u001b[A\n",
            "Generating Images: 100%|██████████| 4/4 [01:14<00:00, 18.72s/it]\u001b[A\n",
            "my_first_flux_lora_v1:  87%|████████▋ | 1749/2000 [1:01:30<09:15,  2.21s/it, lr: 1.0e-04 loss: 4.383e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving at step 1750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1:  87%|████████▋ | 1749/2000 [1:01:32<09:15,  2.21s/it, lr: 1.0e-04 loss: 4.383e-01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/output/my_first_flux_lora_v1/optimizer.pt\n",
            "Removing old save: /content/output/my_first_flux_lora_v1/my_first_flux_lora_v1_000000750.safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "my_first_flux_lora_v1: 100%|█████████▉| 1999/2000 [1:10:15<00:02,  2.11s/it, lr: 1.0e-04 loss: 5.631e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved to /content/output/my_first_flux_lora_v1/optimizer.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fBKs8euHriDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rlgwPrvVn98E",
        "outputId": "19c632ff-f60d-4606-dcb4-6fc39e8d3585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `test` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install transformers safetensors pyyaml\n",
        "\n",
        "# Import libraries\n",
        "import yaml\n",
        "import json\n",
        "import os\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "\n",
        "# Paths\n",
        "model_dir = \"/content/output/my_first_flux_lora_v1\"\n",
        "config_yaml_path = f\"{model_dir}/config.yaml\"\n",
        "config_json_path = f\"{model_dir}/config.json\"\n",
        "checkpoint_file = f\"{model_dir}/my_first_flux_lora_v1_000001750.safetensors\"\n",
        "\n",
        "# Convert config.yaml to config.json\n",
        "with open(config_yaml_path, \"r\") as yaml_file:\n",
        "    config_data = yaml.safe_load(yaml_file)\n",
        "\n",
        "# Create a Hugging Face-compatible JSON configuration\n",
        "hf_config = {\n",
        "    \"model_type\": \"flux\",  # Specify the type of your model; adjust as needed\n",
        "    \"name_or_path\": config_data[\"config\"][\"process\"][0][\"model\"][\"name_or_path\"],\n",
        "    \"quantize\": config_data[\"config\"][\"process\"][0][\"model\"][\"quantize\"],\n",
        "    \"use_ema\": config_data[\"config\"][\"process\"][0][\"train\"][\"ema_config\"][\"use_ema\"],\n",
        "    \"ema_decay\": config_data[\"config\"][\"process\"][0][\"train\"][\"ema_config\"][\"ema_decay\"],\n",
        "    \"dtype\": config_data[\"config\"][\"process\"][0][\"train\"][\"dtype\"],\n",
        "    \"training_steps\": config_data[\"config\"][\"process\"][0][\"train\"][\"steps\"],\n",
        "}\n",
        "\n",
        "# Save as config.json\n",
        "with open(config_json_path, \"w\") as json_file:\n",
        "    json.dump(hf_config, json_file, indent=4)\n",
        "print(f\"Converted config.yaml to {config_json_path}\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "print(\"Tokenizer loaded successfully.\")\n",
        "\n",
        "# Load the model\n",
        "print(\"Loading model...\")\n",
        "model = AutoModel.from_pretrained(model_dir, low_cpu_mem_usage=True)\n",
        "state_dict = load_file(checkpoint_file)  # Load the fine-tuned checkpoint\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Example: Run inference\n",
        "input_text = \"Describe a serene morning by the lake.\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "print(\"Inference complete. Outputs:\", outputs)\n"
      ],
      "metadata": {
        "id": "ZLAq5vZjrnGU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "dd735064-a51f-4fa4-a4cc-f780a369927d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Converted config.yaml to /content/output/my_first_flux_lora_v1/config.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The checkpoint you are trying to load has model type `flux` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'flux'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a6195841445f>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Load the tokenizer and model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokenizer loaded successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                     config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    878\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1037\u001b[0m                     \u001b[0;34mf\"The checkpoint you are trying to load has model type `{config_dict['model_type']}` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                     \u001b[0;34m\"but Transformers does not recognize this architecture. This could be because of an \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The checkpoint you are trying to load has model type `flux` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date."
          ]
        }
      ]
    }
  ]
}